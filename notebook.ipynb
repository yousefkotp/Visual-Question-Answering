{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Question Answering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0\n",
    "%pip install ftfy regex tqdm --user\n",
    "%pip install git+https://github.com/openai/CLIP.git --user\n",
    "%pip install pandas --user\n",
    "%pip install wordcloud --user"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import clip\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import modelArchitecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = 'vizwiz'\n",
    "ANNOTATIONS = INPUT_PATH + '/Annotations/Annotations'\n",
    "TRAIN_PATH = INPUT_PATH + '/train/train'\n",
    "VALIDATION_PATH = INPUT_PATH + '/val/val'\n",
    "ANNOTATIONS_TRAIN_PATH = ANNOTATIONS + '/train.json'\n",
    "ANNOTATIONS_VAL_PATH = ANNOTATIONS + '/val.json'\n",
    "OUTPUT_PATH = ''\n",
    "ANSWER_SPACE = 3129\n",
    "DEVICE  = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(path, output_path, type = 'train'):\n",
    "\n",
    "    output_path +='/dataframes'\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    df = pd.read_json(path)\n",
    "    df = df[['image', 'question', 'answers', 'answer_type', 'answerable']]\n",
    "\n",
    "    # create a new DataFrame to hold the expanded rows\n",
    "    expanded_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    # iterate over each row in the original DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # iterate over each answer in the answers column\n",
    "        for answer in row['answers']:\n",
    "            # create a new row with the current answer\n",
    "            new_row = row.copy()\n",
    "            new_row['answer'] = answer['answer']\n",
    "            new_row['answer_confidence'] = 1 if answer['answer_confidence'] == 'yes' else 0.5 if answer['answer_confidence'] == 'maybe' else 0\n",
    "            # add the new row to the expanded DataFrame\n",
    "            expanded_df = pd.concat([expanded_df, pd.DataFrame(new_row).transpose()], ignore_index=True)\n",
    "    \n",
    "    # Save the expanded DataFrame to a CSV file\n",
    "    if type == 'train':\n",
    "        expanded_df.to_csv(output_path + '/train.csv', index=False)\n",
    "    else:\n",
    "        expanded_df.to_csv(output_path + '/val.csv', index=False)\n",
    "    \n",
    "\n",
    "def load_dataframe(path, type = 'train'):\n",
    "    path += '/dataframes'\n",
    "    if type == 'train':\n",
    "        return pd.read_csv(path + '/train.csv')\n",
    "    else:\n",
    "        return pd.read_csv(path + '/val.csv')\n",
    "    \n",
    "def plot_histogram(dataframe, column):\n",
    "    plt.hist(dataframe[column])\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "\n",
    "def plot_pie(dataframe, column):\n",
    "    plt.pie(dataframe[column].value_counts(), labels = dataframe[column].value_counts().index)\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "\n",
    "def plot_boxplot(dataframe, column):\n",
    "    plt.boxplot(dataframe[column])\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "\n",
    "def plot_wordcloud(dataframe, column):\n",
    "    text = \" \".join([word for word in dataframe[column]])\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                    background_color ='white', \n",
    "                    min_font_size = 10).generate(text) \n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.show()\n",
    "\n",
    "def explore_dataframe(dataframe):\n",
    "\n",
    "    # let's see the distribution of the answer types\n",
    "    plot_pie(dataframe, 'answer_type')\n",
    "\n",
    "    # let's see the distribution of the answerable column\n",
    "    plot_pie(dataframe, 'answerable')\n",
    "\n",
    "    # let's see the distribution of the answer_confidence column\n",
    "    plot_pie(dataframe, 'answer_confidence')\n",
    "\n",
    "    # let's plot histograms for the answer_confidence column\n",
    "    plot_histogram(dataframe, 'answer_confidence')\n",
    "\n",
    "    # let's plot boxplot for the answer_confidence column\n",
    "    plot_boxplot(dataframe, 'answer_confidence')\n",
    "\n",
    "    # let's plot histograms for the answerable column\n",
    "    plot_histogram(dataframe, 'answerable')\n",
    "\n",
    "    # let's see the distribution of the question column\n",
    "    plot_wordcloud(dataframe, 'question')\n",
    "\n",
    "    # let's see the distribution of the answer column\n",
    "    plot_wordcloud(dataframe, 'answer')\n",
    "\n",
    "    # Let's see how many distinct answers we have\n",
    "    print(\"Number of distinct answers: \", get_number_of_distinct_answers(dataframe))\n",
    "\n",
    "def get_number_of_distinct_answers(dataframe):\n",
    "    return len(dataframe['answer'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = create_dataframe(ANNOTATIONS_TRAIN_PATH, OUTPUT_PATH, 'train')\n",
    "val_df = create_dataframe(ANNOTATIONS_VAL_PATH, OUTPUT_PATH, 'val')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_dataframe(OUTPUT_PATH, 'train')\n",
    "val_df = load_dataframe(OUTPUT_PATH, 'val')\n",
    "ANSWER_SPACE = get_number_of_distinct_answers(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will perform EDA on only the train dataset first, then we will perform EDA on the validation dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_dataframe(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_dataframe(val_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelArchitecture.VQAModel(num_classes=10, device= DEVICE, hidden_size=512, model_name=\"RN50x4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizWizDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, path):\n",
    "        self.data = data\n",
    "        self.path = path\n",
    "        self.transform = clip.load('ViT-B/32', device='cuda')\n",
    "        self.tokenizer = clip.tokenize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.path + '/' + self.data[idx]['image']\n",
    "        img = plt.imread(img_path)\n",
    "        img = torch.tensor(img).permute(2, 0, 1)\n",
    "        img = img / 255.0\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.to('cuda')\n",
    "        text = self.data[idx]['question']\n",
    "        text = self.tokenizer(text).to('cuda')\n",
    "        return img, text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
