{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Question Answering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0\n",
    "%pip install ftfy regex tqdm --user\n",
    "%pip install git+https://github.com/openai/CLIP.git --user\n",
    "%pip install pandas --user\n",
    "%pip install wordcloud --user\n",
    "%pip install sklearn --user\n",
    "%pip install scikit-learn --user"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import clip\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import modelArchitecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "INPUT_PATH = 'vizwiz'\n",
    "ANNOTATIONS = INPUT_PATH + '/Annotations/Annotations'\n",
    "TRAIN_PATH = INPUT_PATH + '/train/train'\n",
    "VALIDATION_PATH = INPUT_PATH + '/val/val'\n",
    "ANNOTATIONS_TRAIN_PATH = ANNOTATIONS + '/train.json'\n",
    "ANNOTATIONS_VAL_PATH = ANNOTATIONS + '/val.json'\n",
    "OUTPUT_PATH = ''\n",
    "ANSWER_SPACE = 3129\n",
    "DEVICE  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Device: \", DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(path, output_path, type = 'train'):\n",
    "\n",
    "    output_path +='/dataframes'\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    df = pd.read_json(path)\n",
    "    df = df[['image', 'question', 'answers', 'answer_type', 'answerable']]\n",
    "\n",
    "    # create a new DataFrame to hold the expanded rows\n",
    "    expanded_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    # iterate over each row in the original DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # iterate over each answer in the answers column\n",
    "        for answer in row['answers']:\n",
    "            # create a new row with the current answer\n",
    "            new_row = row.copy()\n",
    "            new_row['answer'] = answer['answer']\n",
    "            new_row['answer_confidence'] = answer['answer_confidence'] #1 if answer['answer_confidence'] == 'yes' else 0.5 if answer['answer_confidence'] == 'maybe' else 0\n",
    "            # add the new row to the expanded DataFrame\n",
    "            expanded_df = pd.concat([expanded_df, pd.DataFrame(new_row).transpose()], ignore_index=True)\n",
    "\n",
    "\n",
    "def save_dataframe(dataframe, path, type = 'train'):\n",
    "\n",
    "    path += '/dataframes'\n",
    "    if type == 'train':\n",
    "        dataframe.to_csv(path + '/train.csv', index=False)\n",
    "    elif type == 'val':\n",
    "        dataframe.to_csv(path + '/val.csv', index=False)\n",
    "    else:\n",
    "        dataframe.to_csv(path + '/test.csv', index=False)\n",
    "\n",
    "def load_dataframe(path, type = 'train'):\n",
    "    path += '/dataframes'\n",
    "    if type == 'train':\n",
    "        return pd.read_csv(path + '/train.csv')\n",
    "    elif type == 'val':\n",
    "        return pd.read_csv(path + '/val.csv')\n",
    "    else:\n",
    "        return pd.read_csv(path + '/test.csv')\n",
    "\n",
    "def split_train_test(dataframe, test_size=0.05):\n",
    "    \n",
    "    # get the unique questions in the dataframe\n",
    "    unique_questions = dataframe['question'].unique()\n",
    "\n",
    "    # get the answer_type and answerable columns\n",
    "    answer_type = dataframe['answer_type']\n",
    "    answerable = dataframe['answerable']\n",
    "\n",
    "    # split the questions into training and testing sets using stratified sampling\n",
    "    train_questions, test_questions, _, _, _, _ = train_test_split(unique_questions, answer_type, answerable, test_size=test_size, stratify=dataframe[['answer_type', 'answerable']], random_state=42)\n",
    "\n",
    "    # create the training and testing dataframes\n",
    "    train_df = dataframe[dataframe['question'].isin(train_questions)]\n",
    "    test_df = dataframe[dataframe['question'].isin(test_questions)]\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def plot_histogram(dataframe, column):\n",
    "    plt.hist(dataframe[column])\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "\n",
    "def plot_pie(dataframe, column):\n",
    "    plt.pie(dataframe[column].value_counts(), labels = dataframe[column].value_counts().index)\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "\n",
    "def plot_boxplot(dataframe, column):\n",
    "    plt.boxplot(dataframe[column])\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "\n",
    "def plot_wordcloud(dataframe, column):\n",
    "    text = \" \".join([word for word in dataframe[column]])\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                    background_color ='white', \n",
    "                    min_font_size = 10).generate(text) \n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.show()\n",
    "\n",
    "def explore_dataframe(dataframe):\n",
    "\n",
    "    # let's see the distribution of the answer types\n",
    "    plot_pie(dataframe, 'answer_type')\n",
    "\n",
    "    # let's see the distribution of the answerable column\n",
    "    plot_pie(dataframe, 'answerable')\n",
    "\n",
    "    # let's see the distribution of the answer_confidence column\n",
    "    plot_pie(dataframe, 'answer_confidence')\n",
    "\n",
    "    # let's plot histograms for the answer_confidence column\n",
    "    plot_histogram(dataframe, 'answer_confidence')\n",
    "\n",
    "    # let's plot boxplot for the answer_confidence column\n",
    "    plot_boxplot(dataframe, 'answer_confidence')\n",
    "\n",
    "    # let's plot histograms for the answerable column\n",
    "    plot_histogram(dataframe, 'answerable')\n",
    "\n",
    "    # let's see the distribution of the question column\n",
    "    plot_wordcloud(dataframe, 'question')\n",
    "\n",
    "    # let's see the distribution of the answer column\n",
    "    plot_wordcloud(dataframe, 'answer')\n",
    "\n",
    "    # Let's see how many distinct answers we have\n",
    "    print(\"Number of distinct answers: \", get_number_of_distinct_answers(dataframe))\n",
    "\n",
    "def get_number_of_distinct_answers(dataframe):\n",
    "    return len(dataframe['answer'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataframes & Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframes\n",
    "train_df = create_dataframe(ANNOTATIONS_TRAIN_PATH, OUTPUT_PATH, 'train')\n",
    "val_df = create_dataframe(ANNOTATIONS_VAL_PATH, OUTPUT_PATH, 'val')\n",
    "train_df, test_df = split_train_test(train_df, 0.05)\n",
    "\n",
    "# Save the dataframes\n",
    "save_dataframe(train_df, OUTPUT_PATH, 'train')\n",
    "save_dataframe(val_df, OUTPUT_PATH, 'val')\n",
    "save_dataframe(test_df, OUTPUT_PATH, 'test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_dataframe(OUTPUT_PATH, 'train')\n",
    "val_df = load_dataframe(OUTPUT_PATH, 'val')\n",
    "test_df = load_dataframe(OUTPUT_PATH, 'test')\n",
    "\n",
    "ANSWER_SPACE = get_number_of_distinct_answers(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_dataframe(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_dataframe(val_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_dataframe(test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelArchitecture.VQAModel(num_classes=10, device= DEVICE, hidden_size=512, model_name=\"RN50x4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizWizDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, path):\n",
    "        self.data = data\n",
    "        self.path = path\n",
    "        self.transform = clip.load('ViT-B/32', device='cuda')\n",
    "        self.tokenizer = clip.tokenize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.path + '/' + self.data[idx]['image']\n",
    "        img = plt.imread(img_path)\n",
    "        img = torch.tensor(img).permute(2, 0, 1)\n",
    "        img = img / 255.0\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.to('cuda')\n",
    "        text = self.data[idx]['question']\n",
    "        text = self.tokenizer(text).to('cuda')\n",
    "        return img, text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
